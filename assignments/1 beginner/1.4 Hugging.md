# 1.4 Huggingface

## 1. 模型下载
通过huggingface的hub可以方便地下载各种预训练模型，包括今天要下载的`internlm2-chat-1_8b`
> 如有需要的库，请先安装：`pip install -U <库名>`

### 利用`Transformers`库直接下载
```python
# Load model directly
from transformers import AutoModelForCausalLM

model = AutoModelForCausalLM.from_pretrained(
    "internlm/internlm2-chat-1_8b", trust_remote_code=True
)
```
模型会被下载到`~/.cache/huggingface/transformers`目录下，而且无需重复下载。下载途中如果网络出现问题，可以再次运行命令，会自动跳过已下载的部分。

### 使用`Git`下载
```
git lfs install
GIT_LFS_SKIP_SMUDGE=1 # 跳过文件的复制，直接创建指向远程仓库的指针文件
git clone git@hf.co:internlm/internlm2-chat-1_8b.git
```
### 使用`huggingface_hub`库下载
```python
from huggingface_hub import snapshot_download

local_dir = "/downloads/"
snapshot_download(
    repo_id="internlm/internlm2-chat-1_8b", allow_patterns="*.json", local_dir=local_dir
)
```
> `allow_patterns`参数用于指定下载的文件模式，这里我们只下载JSON格式的文件，包括任务要求的两个文件

### 使用`hf_transfer`库高速下载
```
pip install "huggingface_hub[hf_transfer]"
HF_HUB_ENABLE_HF_TRANSFER=1 huggingface-cli download internlm/internlm2-chat-1_8b --include="*.json"
```
> 没尝试过，但是看起来很厉害的样子。

## 2. 模型上传
### 创建一个Hugging Face Space
[space](https://huggingface.co/spaces/ranshenhai/intern_cobuild)

### 克隆Space到本地
> Hugging Face提供了Git下载Space文件，可以考虑在本仓库建立一个`submodule`或者直接clone下来。

```
git submodule add https://huggingface.co/spaces/ranshenhai/intern_cobuild
```

## 3. Space上传
> 公司内网限制太多，先跳过继续。